{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', sep = '\\t', names = ['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "> Spam == 1, Ham == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: The entire dataframe is our corpus, each row is considered its own document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Class Balance\n",
    "\n",
    "We want to get a sense for our \"baseline accuracy\" or the distribution of spam versus ham.  It's called the baseline because if we were to simply calculate our 1's (spam) with brute force (label everything as spam) we would be right X amount of the time. It's obviously easy to improve upon that brute force model, but we also have an idea of how accurate we would be with a shitty model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize = True) # normalize converts counts to percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> That's pretty unbalanced... we've got a lotta ham in here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Target & Features, TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message'] # note: one bracket for series to pass into CountVectorizer\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: notice the `stratify` parameter above. This retains the class distribution of our target variable that we checked above (~87/13 split ham/spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Now we're ready to have our data go through a pipeline like so:\n",
    "- Step 1: Pass X through the Count Vectorizer\n",
    "- Step 2: Feed data into our model\n",
    "    - NOTE: We are using a `MultinomialNB` model because when we tokenize our data with `CountVectorizer` we will have far more than two binary classes.\n",
    "\n",
    "\n",
    "**NOTE About Pipelines**  \n",
    "Pipelines are lists of tuples; each stage in the pipeline (above) is its own separate tuple. The first param of the tuple must be a string value. By convention, it makes your life easier if the string value is the exact same name as the variable you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv), # step 1 above\n",
    "    ('model', model) # step 2 above\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "At this point, we would normally cross-validate to check the performance of our model. `GridSearchCV` obviously has that built-in, so we get it all in one step. We're going to pass in two parameters to `GridSearchCV` to optimize our model:  \n",
    "1. Our `pipeline`\n",
    "2. Our `param_grid` that we wish to optimize  \n",
    "\n",
    "**NOTE:** For purposes of this tutorial, we will spend more time tuning the parameters of `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid = {})\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825317061497966"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: The score above represents our 3-fold cross-validation score from the `GridSearchCV`. That is the default number of folds but we can change it with the `cv` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863603732950467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4747           Orh i tot u say she now still dun believe.\n",
       "5295    Alex says he's not ok with you not being ok wi...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "4654     Lol yes. But it will add some spice to your day.\n",
       "1133                  Good morning princess! How are you?\n",
       "944     And also I've sorta blown him off a couple tim...\n",
       "357     Congratulations ur awarded 500 of CD vouchers ...\n",
       "2290    Had your mobile 11mths ? Update for FREE to Or...\n",
       "3964        If you ask her or she say any please message.\n",
       "3734                Old Orchard near univ. How about you?\n",
       "1200    NEFT Transaction with reference number  &lt;#&...\n",
       "394     Yes i think so. I am in office but my lap is i...\n",
       "4136    No need to say anything to me. I know i am an ...\n",
       "1375    500 New Mobiles from 2004, MUST GO! Txt: NOKIA...\n",
       "4494    LOL .. *grins* .. I'm not babe, but thanks for...\n",
       "713                 08714712388 between 10am-7pm Cost 10p\n",
       "5561    Get me out of this dump heap. My mom decided t...\n",
       "2644    Hi! You just spoke to MANEESHA V. We'd like to...\n",
       "291                 Hey you told your name to gautham ah?\n",
       "2101      Oh Howda gud gud.. Mathe en samachara chikku:-)\n",
       "4813       fyi I'm at usf now, swing by the room whenever\n",
       "1166          Haha yeah I see that now, be there in a sec\n",
       "5036    How many times i told in the stage all use to ...\n",
       "3151          Yo! Howz u? girls never rang after india. L\n",
       "3327    Huh so fast... Dat means u havent finished pai...\n",
       "3243    Good Morning my Dear........... Have a great &...\n",
       "4875                     Wat happened to the cruise thing\n",
       "5038                         (You didn't hear it from me)\n",
       "4379        Doing nothing, then u not having dinner w us?\n",
       "5360    Hey, iouri gave me your number, I'm wylie, rya...\n",
       "                              ...                        \n",
       "5150    Happy new year to u and ur family...may this n...\n",
       "1725              There bold 2  &lt;#&gt; . Is that yours\n",
       "3196    Great. P diddy is my neighbor and comes for to...\n",
       "2250    Thanks for your ringtone order, ref number R83...\n",
       "737     Thanks for looking out for me. I really apprec...\n",
       "1677    Yeah, that's fine! It's £6 to get in, is that ...\n",
       "4420    How have your little darlings been so far this...\n",
       "5312    Here got ur favorite oyster... N got my favori...\n",
       "797     Orange customer, you may now claim your FREE C...\n",
       "434                             Booked ticket for pongal?\n",
       "3416                        He remains a bro amongst bros\n",
       "1651    I dont have any of your file in my bag..i was ...\n",
       "205                             U call me alter at 11 ok.\n",
       "1089    You are awarded a SiPix Digital Camera! call 0...\n",
       "289     My life Means a lot to me, Not because I love ...\n",
       "1628    You have been selected to stay in 1 of 250 top...\n",
       "603                Speaking of does he have any cash yet?\n",
       "2718                                       Okie.. Thanx..\n",
       "4471    Lemme know when I can swing by and pick up, I'...\n",
       "2851    She's fine. Good to hear from you. How are you...\n",
       "1560    Single line with a big meaning::::: \"Miss anyt...\n",
       "1208                I need you to be in my strong arms...\n",
       "895     Doesn't g have class early tomorrow and thus s...\n",
       "3438                        Then what about further plan?\n",
       "4214                     I attended but nothing is there.\n",
       "2329        That day you asked about anand number. Why:-)\n",
       "1932                  What pa tell me.. I went to bath:-)\n",
       "5316                         Jus finish watching tv... U?\n",
       "3217    URGENT! We are trying to contact U. Todays dra...\n",
       "762     We are at grandmas. Oh dear, u still ill? I fe...\n",
       "Name: message, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What's so cool about this? Well, you'll notice that our `X_train` data is \"unmodified\" from our original TTS. THIS is the beauty of `Pipeline`.  Here's what's happening:\n",
    "- We instantiated a `CountVectorizer` and a `MultinomialNB` model above\n",
    "- We put them into a `Pipeline` to serve as a \"de facto\" model that we can pass into `GridSearchCV`\n",
    "- We called the grid search on our pipeline and fit it to our training data set\n",
    "- Pipeline took care of the rest, and now we don't have to refit or scale or anything else, we can simply tune our parameters in `GridSearchCV` to optimize our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note About Workflows\n",
    "So at this point our workflow has been set up above. To illustrate the beauty of `Pipeline` I'm going to leave it as is, and just restart the grid search below. In a normal environment, you would just start playing with the grid search `param_grid` but I don't want to mess up the workbook flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cv__stop_words': [None, 'english'], 'cv__max_features': [3000, 4000], 'cv__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    # NOTE: we need to tell GridSearchCV which model's params we want to tune; that's what the cv__ is for\n",
    "    'cv__stop_words': [None, 'english'], # GridSearchCV will determine which is better\n",
    "    'cv__max_features': [3000, 4000],\n",
    "    'cv__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 3000, 'cv__ngram_range': (1, 2), 'cv__stop_words': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check best params\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844460397224216"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- How can I interpret the results of this? For example, can I inspect most popular words in each document? How?\n",
    "- Lemmatizing... Do I take care of that before even splitting up into TTS?\n",
    "- Can you only run one model at a time in `Pipeline`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more thingy\n",
    "The `binary` param in `CountVectorizer` simply states whether a word appeared in the document (`1`) or it didn't (`0`); it doesn't count the number of individual words. Riley points out in his video that this would be a good use-case for the `BernoulliNB` model instead of `MultinomialNB`. We're going to pull that into the pipeline and see how it performs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary = True)\n",
    "model = BernoulliNB()\n",
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=No...cabulary=None)), ('model', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cv__stop_words': [None, 'english'], 'cv__max_features': [3000, 4000], 'cv__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    # NOTE: we need to tell GridSearchCV which model's params we want to tune; that's what the cv__ is for\n",
    "    'cv__stop_words': [None, 'english'], # GridSearchCV will determine which is better\n",
    "    'cv__max_features': [3000, 4000],\n",
    "    'cv__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 3000, 'cv__ngram_range': (1, 2), 'cv__stop_words': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808566642737497"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777458722182341"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'E' for Effort, but it's actually worse than the original pipeline with `MultinomialNB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
